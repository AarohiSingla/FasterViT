{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3517351d-179b-4de2-83a7-af829f3a2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30aa4fdc-6619-4d5d-a766-48ba21637d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'rock', 'scissors']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = 'RockPaperScissorsDataset'\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "dataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d0f300-fed1-468a-89d0-47e583ab2574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4abb7608-e915-4229-b52b-4f36928939ea",
   "metadata": {},
   "source": [
    "First, let's print the model architecture to understand its structure:\n",
    "\n",
    "Run the above code to see the structure of the model. Look for the final layer that produces the class scores, typically named something like classifier, head, or fc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba171da-e9d2-43ea-a4a4-c98a28977dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\faster_ViT_env\\myvenv\\Lib\\site-packages\\torch\\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3550.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FasterViT(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Identity()\n",
      "    (conv_down): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (levels): ModuleList(\n",
      "    (0): FasterViTLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_path): DropPath(drop_prob=0.013)\n",
      "        )\n",
      "      )\n",
      "      (downsample): Downsample(\n",
      "        (norm): LayerNorm2d((64,), eps=1e-06, elementwise_affine=True)\n",
      "        (reduction): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): FasterViTLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): ConvBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_path): DropPath(drop_prob=0.027)\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_path): DropPath(drop_prob=0.040)\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act1): GELU(approximate='none')\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (drop_path): DropPath(drop_prob=0.053)\n",
      "        )\n",
      "      )\n",
      "      (downsample): Downsample(\n",
      "        (norm): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
      "        (reduction): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): FasterViTLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.067)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (hat_mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_drop_path): DropPath(drop_prob=0.067)\n",
      "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (upsampler): Upsample(size=7, mode='nearest')\n",
      "        )\n",
      "        (1): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.080)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (hat_mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_drop_path): DropPath(drop_prob=0.080)\n",
      "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (upsampler): Upsample(size=7, mode='nearest')\n",
      "        )\n",
      "        (2): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.093)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (hat_mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_drop_path): DropPath(drop_prob=0.093)\n",
      "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (upsampler): Upsample(size=7, mode='nearest')\n",
      "        )\n",
      "        (3): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.107)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (hat_mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_drop_path): DropPath(drop_prob=0.107)\n",
      "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (upsampler): Upsample(size=7, mode='nearest')\n",
      "        )\n",
      "        (4): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.120)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (hat_mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_drop_path): DropPath(drop_prob=0.120)\n",
      "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (upsampler): Upsample(size=7, mode='nearest')\n",
      "        )\n",
      "        (5): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.133)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (hat_attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=8, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (hat_mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (hat_drop_path): DropPath(drop_prob=0.133)\n",
      "          (hat_pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=256, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (upsampler): Upsample(size=7, mode='nearest')\n",
      "        )\n",
      "      )\n",
      "      (downsample): Downsample(\n",
      "        (norm): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (reduction): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (global_tokenizer): TokenInitializer(\n",
      "        (pos_embed): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        (to_global_feature): Sequential(\n",
      "          (pos): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (pool): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): FasterViTLayer(\n",
      "      (blocks): ModuleList(\n",
      "        (0): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.147)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.160)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.173)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.187)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): HAT(\n",
      "          (pos_embed): PosEmbMLPSwinv1D(\n",
      "            (cpb_mlp): Sequential(\n",
      "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "              (1): ReLU()\n",
      "              (2): Linear(in_features=512, out_features=512, bias=False)\n",
      "            )\n",
      "          )\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (pos_emb_funct): PosEmbMLPSwinv2D(\n",
      "              (cpb_mlp): Sequential(\n",
      "                (0): Linear(in_features=2, out_features=512, bias=True)\n",
      "                (1): ReLU(inplace=True)\n",
      "                (2): Linear(in_features=512, out_features=16, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (drop_path): DropPath(drop_prob=0.200)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (head): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define the Model\n",
    "# Load the FasterViT model and modify it for your number of classes.\n",
    "\n",
    "from fastervit import create_model\n",
    "\n",
    "# Load FasterViT model\n",
    "model = create_model('faster_vit_0_224', \n",
    "                     pretrained=True,\n",
    "                     model_path=\"tmp/faster_vit_0.pth.tar\")\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361b7d2-e6f3-42dd-bb47-2159c719f775",
   "metadata": {},
   "source": [
    "\n",
    "From the model architecture, it looks like the final classification layer is named head. \n",
    "\n",
    "To modify this layer for your custom classification task, you should replace the head layer with a new Linear layer that has the appropriate number of output classes for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92fdfaa6-ddf2-4722-9fd2-b37974e2b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modify the final layer for custom classification\n",
    "num_ftrs = model.head.in_features\n",
    "model.head = torch.nn.Linear(num_ftrs, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb17b419-3d91-490d-88d2-9c3980f6aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5beab8e2-0942-4465-97bf-c637d384f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Learning rate scheduler\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c233b42-0a58-4fae-be89-a6db6cbd7c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.8346 Acc: 0.7202\n",
      "val Loss: 0.4109 Acc: 0.9946\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.4181 Acc: 0.8750\n",
      "val Loss: 0.1203 Acc: 1.0000\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.2697 Acc: 0.9115\n",
      "val Loss: 0.0723 Acc: 1.0000\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.2665 Acc: 0.9020\n",
      "val Loss: 0.1885 Acc: 0.9328\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2348 Acc: 0.9079\n",
      "val Loss: 0.0690 Acc: 0.9839\n",
      "\n",
      "Training complete in 1m 32s\n",
      "Best val Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:.4f}')\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=5)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'faster_vit_custom_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f2713-6efd-4531-b8ad-7bdc195cf69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "724f4a16-ffda-49eb-be2c-4507b0b41fd5",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3074929f-0717-4f8b-8bcc-7018b6254b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from fastervit import create_model\n",
    "\n",
    "# Define the number of classes in your custom dataset\n",
    "num_classes = 3  # Replace with your actual number of classes\n",
    "\n",
    "# Create the model architecture\n",
    "model = create_model('faster_vit_0_224', pretrained=False)\n",
    "\n",
    "# Modify the final classification layer to match the number of classes in your custom dataset\n",
    "model.head = torch.nn.Linear(model.head.in_features, num_classes)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load('faster_vit_custom_model.pth'))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define data transformations for the input image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = preprocess(image)\n",
    "    image = image.unsqueeze(0)  # Add batch dimension\n",
    "    return image.to(device)\n",
    "\n",
    "# Function to make predictions\n",
    "def predict(image_path, model, class_names):\n",
    "    image = load_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predicted_class = class_names[preds.item()]\n",
    "    return predicted_class\n",
    "\n",
    "# List of class names (ensure this matches your custom dataset's classes)\n",
    "class_names = ['paper', 'rock', 'scissors']  # Replace with your actual class names\n",
    "\n",
    "# Example usage\n",
    "image_path = 'RockPaperScissorsDataset\\\\test\\\\rock\\\\rock2_png.rf.baa4a80a096a58d85ba7c79bd8cd0a74.jpg'\n",
    "predicted_class = predict(image_path, model, class_names)\n",
    "print(predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5631fddf-47f2-4b91-8403-719e8d6094de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output image with prediction: output_with_prediction.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "# Function to make predictions and draw the label on the image\n",
    "def predict_and_draw(image_path, model, class_names):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predicted_class = class_names[preds.item()]\n",
    "    \n",
    "    # Draw the predicted class on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "    text = f'Predicted: {predicted_class}'\n",
    "    \n",
    "    # Get the size of the text\n",
    "    text_bbox = draw.textbbox((10, 10), text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "    \n",
    "    # Position the text at the top left corner\n",
    "    text_position = (10, 10)\n",
    "    draw.rectangle([text_position, (text_position[0] + text_width, text_position[1] + text_height)], fill=\"black\")\n",
    "    draw.text(text_position, text, fill=\"white\", font=font)\n",
    "    \n",
    "    # Display the image\n",
    "    image.show()\n",
    "    \n",
    "    # Save the image with the prediction text\n",
    "    output_image_path = \"output_with_prediction.jpg\"\n",
    "    image.save(output_image_path)\n",
    "    print(f\"Saved output image with prediction: {output_image_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# List of class names (ensure this matches your custom dataset's classes)\n",
    "class_names = ['paper', 'rock', 'scissors']  # Replace with your actual class names\n",
    "\n",
    "# Example usage\n",
    "image_path = 'RockPaperScissorsDataset\\\\test\\\\rock\\\\rock2_png.rf.baa4a80a096a58d85ba7c79bd8cd0a74.jpg'\n",
    "predict_and_draw(image_path, model, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d4c6e-5bb0-4551-9fd0-d7c95d3db2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab76be-e124-4444-9466-736602a2ca72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
